---
File: tests/unit/__init__.py
---
# tests/unit/__init__.py
"""Unit tests - no database required."""



---
File: tests/unit/conftest.py
---
# tests/unit/conftest.py
"""Fixtures for unit tests - no database required."""

import uuid
from datetime import datetime, timezone
from unittest.mock import MagicMock, patch

import pytest


# ============================================================
# Sample Data Fixtures - ChatGPT Format
# ============================================================

@pytest.fixture
def chatgpt_simple_conversation() -> dict:
    """Simple linear ChatGPT conversation (no branches)."""
    root_id = str(uuid.uuid4())
    msg1_id = str(uuid.uuid4())
    msg2_id = str(uuid.uuid4())
    msg3_id = str(uuid.uuid4())
    msg4_id = str(uuid.uuid4())
    
    return {
        "conversation_id": "conv-simple-001",
        "title": "Simple Test Conversation",
        "create_time": 1700000000.0,
        "update_time": 1700001000.0,
        "mapping": {
            root_id: {
                "id": root_id,
                "parent": None,
                "children": [msg1_id],
                "message": None
            },
            msg1_id: {
                "id": msg1_id,
                "parent": root_id,
                "children": [msg2_id],
                "message": {
                    "id": msg1_id,
                    "author": {"role": "user"},
                    "create_time": 1700000100.0,
                    "content": {
                        "content_type": "text",
                        "parts": ["Hello, how are you?"]
                    }
                }
            },
            msg2_id: {
                "id": msg2_id,
                "parent": msg1_id,
                "children": [msg3_id],
                "message": {
                    "id": msg2_id,
                    "author": {"role": "assistant"},
                    "create_time": 1700000200.0,
                    "content": {
                        "content_type": "text",
                        "parts": ["I'm doing well, thank you!"]
                    }
                }
            },
            msg3_id: {
                "id": msg3_id,
                "parent": msg2_id,
                "children": [msg4_id],
                "message": {
                    "id": msg3_id,
                    "author": {"role": "user"},
                    "create_time": 1700000300.0,
                    "content": {
                        "content_type": "text",
                        "parts": ["Explain Python decorators."]
                    }
                }
            },
            msg4_id: {
                "id": msg4_id,
                "parent": msg3_id,
                "children": [],
                "message": {
                    "id": msg4_id,
                    "author": {"role": "assistant"},
                    "create_time": 1700000400.0,
                    "content": {
                        "content_type": "text",
                        "parts": ["Python decorators are functions that modify other functions.\n\n```python\ndef decorator(func):\n    pass\n```"]
                    }
                }
            }
        }
    }


@pytest.fixture
def claude_simple_conversation() -> dict:
    """Simple Claude conversation."""
    return {
        "uuid": "claude-conv-001",
        "name": "Claude Test Conversation",
        "created_at": "2024-01-15T10:00:00Z",
        "updated_at": "2024-01-15T10:30:00Z",
        "chat_messages": [
            {
                "uuid": "claude-msg-001",
                "sender": "human",
                "created_at": "2024-01-15T10:00:00Z",
                "content": [
                    {"type": "text", "text": "Hello Claude!"}
                ]
            },
            {
                "uuid": "claude-msg-002",
                "sender": "assistant",
                "created_at": "2024-01-15T10:01:00Z",
                "content": [
                    {"type": "text", "text": "Hello! How can I help you today?"}
                ]
            },
        ]
    }


# ============================================================
# Mock Session Fixture
# ============================================================

@pytest.fixture
def mock_session():
    """Create a mock SQLAlchemy session for unit tests."""
    session = MagicMock()
    session.query.return_value.filter.return_value.first.return_value = None
    session.query.return_value.filter.return_value.all.return_value = []
    session.query.return_value.count.return_value = 0
    return session



---
File: tests/unit/test_annotations.py
---
# tests/unit/test_annotations.py
"""Unit tests for annotation infrastructure."""

import pytest
from uuid import uuid4

from llm_archive.annotations.core import (
    EntityType,
    ValueType,
    AnnotationResult,
    AnnotationWriter,
    AnnotationReader,
)


# ============================================================
# AnnotationResult Tests
# ============================================================

class TestAnnotationResult:
    """Test AnnotationResult dataclass."""
    
    def test_create_flag_result(self):
        """Flag results only need key."""
        result = AnnotationResult(
            key='has_code',
            value_type=ValueType.FLAG,
        )
        assert result.key == 'has_code'
        assert result.value is None
        assert result.value_type == ValueType.FLAG
    
    def test_create_string_result(self):
        """String results need key and value."""
        result = AnnotationResult(
            key='exchange_type',
            value='wiki_article',
            value_type=ValueType.STRING,
            confidence=0.9,
            reason='wiki_links_detected',
        )
        assert result.key == 'exchange_type'
        assert result.value == 'wiki_article'
        assert result.value_type == ValueType.STRING
        assert result.confidence == 0.9
        assert result.reason == 'wiki_links_detected'
    
    def test_create_numeric_result(self):
        """Numeric results need key and numeric value."""
        result = AnnotationResult(
            key='wiki_link_count',
            value=5,
            value_type=ValueType.NUMERIC,
        )
        assert result.key == 'wiki_link_count'
        assert result.value == 5
        assert result.value_type == ValueType.NUMERIC
    
    def test_create_json_result(self):
        """JSON results can store complex data."""
        result = AnnotationResult(
            key='metadata',
            value={'domains': ['example.com', 'test.org']},
            value_type=ValueType.JSON,
        )
        assert result.key == 'metadata'
        assert result.value == {'domains': ['example.com', 'test.org']}
        assert result.value_type == ValueType.JSON
    
    def test_default_value_type_is_string(self):
        """Default value_type should be STRING."""
        result = AnnotationResult(key='title', value='Test Title')
        assert result.value_type == ValueType.STRING
    
    def test_default_source_is_heuristic(self):
        """Default source should be 'heuristic'."""
        result = AnnotationResult(key='test', value='value')
        assert result.source == 'heuristic'


# ============================================================
# EntityType and ValueType Enum Tests
# ============================================================

class TestEnums:
    """Test EntityType and ValueType enums."""
    
    def test_entity_types(self):
        """All expected entity types exist."""
        assert EntityType.CONTENT_PART.value == 'content_part'
        assert EntityType.MESSAGE.value == 'message'
        assert EntityType.PROMPT_RESPONSE.value == 'prompt_response'
        assert EntityType.DIALOGUE.value == 'dialogue'
    
    def test_value_types(self):
        """All expected value types exist."""
        assert ValueType.FLAG.value == 'flag'
        assert ValueType.STRING.value == 'string'
        assert ValueType.NUMERIC.value == 'numeric'
        assert ValueType.JSON.value == 'json'


# ============================================================
# AnnotationWriter Tests (mock-based, no DB)
# ============================================================

class TestAnnotationWriterInterface:
    """Test AnnotationWriter interface without database."""
    
    def test_table_name_generation(self):
        """Test table name generation for entity/value type combos."""
        # Can't instantiate without session, but can test the pattern
        template = "derived.{entity}_annotations_{value_type}"
        
        assert template.format(
            entity='message', value_type='string'
        ) == 'derived.message_annotations_string'
        
        assert template.format(
            entity='content_part', value_type='flag'
        ) == 'derived.content_part_annotations_flag'
        
        assert template.format(
            entity='prompt_response', value_type='numeric'
        ) == 'derived.prompt_response_annotations_numeric'


# ============================================================
# Integration test fixtures (require database)
# ============================================================

@pytest.fixture
def db_session():
    """
    Create a database session for integration tests.
    
    This fixture is a placeholder - actual implementation would
    need a test database setup.
    """
    pytest.skip("Requires database setup")


class TestAnnotationWriterIntegration:
    """Integration tests for AnnotationWriter (require database)."""
    
    def test_write_flag_creates_record(self, db_session):
        """Writing a flag creates a record in flag table."""
        writer = AnnotationWriter(db_session)
        entity_id = uuid4()
        
        result = writer.write_flag(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='has_code',
            source='test',
        )
        
        assert result is True
        # Verify record exists
        reader = AnnotationReader(db_session)
        assert reader.has_flag(EntityType.MESSAGE, entity_id, 'has_code')
    
    def test_write_string_creates_record(self, db_session):
        """Writing a string creates a record in string table."""
        writer = AnnotationWriter(db_session)
        entity_id = uuid4()
        
        result = writer.write_string(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='gizmo_id',
            value='g-12345',
            source='test',
        )
        
        assert result is True
        reader = AnnotationReader(db_session)
        values = reader.get_string(EntityType.MESSAGE, entity_id, 'gizmo_id')
        assert 'g-12345' in values
    
    def test_write_duplicate_flag_returns_false(self, db_session):
        """Writing duplicate flag returns False (no new record)."""
        writer = AnnotationWriter(db_session)
        entity_id = uuid4()
        
        # First write succeeds
        result1 = writer.write_flag(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='has_code',
            source='test',
        )
        assert result1 is True
        
        # Duplicate returns False
        result2 = writer.write_flag(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='has_code',
            source='test',
        )
        assert result2 is False
    
    def test_write_multi_value_string(self, db_session):
        """Can write multiple values for same string key."""
        writer = AnnotationWriter(db_session)
        entity_id = uuid4()
        
        writer.write_string(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='tag',
            value='coding',
            source='test',
        )
        writer.write_string(
            entity_type=EntityType.MESSAGE,
            entity_id=entity_id,
            key='tag',
            value='python',
            source='test',
        )
        
        reader = AnnotationReader(db_session)
        values = reader.get_string(EntityType.MESSAGE, entity_id, 'tag')
        assert set(values) == {'coding', 'python'}


class TestAnnotationReaderIntegration:
    """Integration tests for AnnotationReader (require database)."""
    
    def test_find_entities_with_flag(self, db_session):
        """Can find all entities with a specific flag."""
        writer = AnnotationWriter(db_session)
        
        # Create some flagged entities
        id1, id2, id3 = uuid4(), uuid4(), uuid4()
        writer.write_flag(EntityType.MESSAGE, id1, 'has_code', source='test')
        writer.write_flag(EntityType.MESSAGE, id2, 'has_code', source='test')
        writer.write_flag(EntityType.MESSAGE, id3, 'has_attachment', source='test')
        
        reader = AnnotationReader(db_session)
        results = reader.find_entities_with_flag(EntityType.MESSAGE, 'has_code')
        
        assert id1 in results
        assert id2 in results
        assert id3 not in results
    
    def test_find_entities_with_string_value(self, db_session):
        """Can find entities with specific string value."""
        writer = AnnotationWriter(db_session)
        
        id1, id2 = uuid4(), uuid4()
        writer.write_string(EntityType.MESSAGE, id1, 'gizmo_id', 'g-wiki', source='test')
        writer.write_string(EntityType.MESSAGE, id2, 'gizmo_id', 'g-other', source='test')
        
        reader = AnnotationReader(db_session)
        results = reader.find_entities_with_string(
            EntityType.MESSAGE, 'gizmo_id', 'g-wiki'
        )
        
        assert id1 in results
        assert id2 not in results



---
File: tests/unit/test_chatgpt_extractor_annotations.py
---
# tests/unit/test_chatgpt_extractor_annotations.py
"""Unit tests for ChatGPT extractor annotation integration.

These tests verify that the ChatGPT extractor correctly writes
annotations during ingestion for:
- gizmo_id (string annotation on messages)
- has_gizmo (flag annotation on messages)
- model_slug (string annotation on messages)
- Canvas metadata (annotations on content_parts)
"""

import pytest
from uuid import uuid4


# ============================================================
# Test data fixtures
# ============================================================

def make_message_data(
    msg_id: str = None,
    role: str = 'assistant',
    content: str = 'Test content',
    gizmo_id: str = None,
    model_slug: str = None,
    canvas: dict = None,
) -> dict:
    """Create mock ChatGPT message data."""
    msg_id = msg_id or str(uuid4())
    
    metadata = {}
    if gizmo_id:
        metadata['gizmo_id'] = gizmo_id
    if model_slug:
        metadata['model_slug'] = model_slug
    if canvas:
        metadata['canvas'] = canvas
    
    return {
        'id': msg_id,
        'author': {
            'role': role,
            'name': None,
            'metadata': {},
        },
        'content': {
            'content_type': 'text',
            'parts': [content] if content else [],
        },
        'metadata': metadata,
        'create_time': 1700000000,
        'update_time': 1700000000,
        'status': 'finished',
        'end_turn': True,
    }


def make_canvas_data(
    textdoc_id: str = 'doc-123',
    version: int = 1,
    title: str = 'Test Canvas',
    textdoc_type: str = 'document',
    content: str = 'Canvas content here',
) -> dict:
    """Create mock canvas data."""
    return {
        'textdoc_id': textdoc_id,
        'version': version,
        'title': title,
        'textdoc_type': textdoc_type,
        'content': content,
        'from_version': version - 1 if version > 1 else None,
        'textdoc_content_length': len(content) if content else 0,
        'has_user_edit': False,
    }


# ============================================================
# Unit tests (no database required)
# ============================================================

class TestMessageDataConstruction:
    """Test message data fixture construction."""
    
    def test_basic_message_data(self):
        """Basic message data should have required fields."""
        data = make_message_data()
        
        assert 'id' in data
        assert data['author']['role'] == 'assistant'
        assert data['content']['parts'] == ['Test content']
    
    def test_message_with_gizmo(self):
        """Message with gizmo_id should have it in metadata."""
        data = make_message_data(gizmo_id='g-wiki-generator')
        
        assert data['metadata']['gizmo_id'] == 'g-wiki-generator'
    
    def test_message_with_model(self):
        """Message with model_slug should have it in metadata."""
        data = make_message_data(model_slug='gpt-4')
        
        assert data['metadata']['model_slug'] == 'gpt-4'
    
    def test_message_with_canvas(self):
        """Message with canvas should have canvas in metadata."""
        canvas = make_canvas_data(title='My Document')
        data = make_message_data(canvas=canvas)
        
        assert data['metadata']['canvas']['title'] == 'My Document'


class TestCanvasDataConstruction:
    """Test canvas data fixture construction."""
    
    def test_basic_canvas_data(self):
        """Basic canvas data should have required fields."""
        canvas = make_canvas_data()
        
        assert canvas['textdoc_id'] == 'doc-123'
        assert canvas['version'] == 1
        assert canvas['title'] == 'Test Canvas'
        assert canvas['textdoc_type'] == 'document'
    
    def test_canvas_version_tracking(self):
        """Canvas with version > 1 should have from_version."""
        canvas = make_canvas_data(version=3)
        
        assert canvas['from_version'] == 2
    
    def test_canvas_first_version(self):
        """First version canvas should have from_version=None."""
        canvas = make_canvas_data(version=1)
        
        assert canvas['from_version'] is None


# ============================================================
# Integration tests (require database)
# ============================================================

@pytest.fixture
def db_session():
    """
    Create a database session for integration tests.
    
    This fixture is a placeholder - actual implementation would
    need a test database setup with schema applied.
    """
    pytest.skip("Requires database setup with schema")


class TestChatGPTExtractorGizmoAnnotations:
    """Test gizmo annotation writing during extraction."""
    
    def test_extracts_gizmo_id_annotation(self, db_session):
        """Gizmo ID should be written as message string annotation."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        from llm_archive.annotations import AnnotationReader, EntityType
        
        extractor = ChatGPTExtractor(db_session)
        
        # Create a dialogue with a message using a gizmo
        dialogue_data = {
            'conversation_id': 'test-conv-1',
            'title': 'Test Conversation',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(
                        msg_id='msg-1',
                        gizmo_id='g-wiki-generator',
                    ),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        assert result == 'new'
        
        # Verify annotation was written
        reader = AnnotationReader(db_session)
        # Would need to resolve the message ID to verify
    
    def test_extracts_has_gizmo_flag(self, db_session):
        """has_gizmo flag should be written for messages with gizmo."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        
        extractor = ChatGPTExtractor(db_session)
        
        dialogue_data = {
            'conversation_id': 'test-conv-2',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(
                        msg_id='msg-1',
                        gizmo_id='g-test',
                    ),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        assert result == 'new'
    
    def test_no_gizmo_annotation_when_missing(self, db_session):
        """Messages without gizmo should not have gizmo annotations."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        
        extractor = ChatGPTExtractor(db_session)
        
        dialogue_data = {
            'conversation_id': 'test-conv-3',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(
                        msg_id='msg-1',
                        gizmo_id=None,  # No gizmo
                    ),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        assert result == 'new'


class TestChatGPTExtractorCanvasAnnotations:
    """Test canvas annotation writing during extraction."""
    
    def test_extracts_canvas_as_content_part(self, db_session):
        """Canvas should be created as content_part with type='canvas'."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        from llm_archive.models import ContentPart
        
        extractor = ChatGPTExtractor(db_session)
        
        canvas = make_canvas_data(
            textdoc_id='doc-abc',
            version=1,
            title='My Wiki Article',
            content='Article content here',
        )
        
        dialogue_data = {
            'conversation_id': 'test-conv-canvas',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(
                        msg_id='msg-1',
                        content='Here is your document',
                        canvas=canvas,
                    ),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        assert result == 'new'
        
        # Verify canvas content_part was created
        canvas_parts = db_session.query(ContentPart).filter(
            ContentPart.part_type == 'canvas'
        ).all()
        
        assert len(canvas_parts) >= 1
    
    def test_canvas_title_annotation(self, db_session):
        """Canvas title should be written as content_part annotation."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        from llm_archive.annotations import AnnotationReader, EntityType
        
        extractor = ChatGPTExtractor(db_session)
        
        canvas = make_canvas_data(title='Important Document')
        
        dialogue_data = {
            'conversation_id': 'test-conv-canvas-title',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(canvas=canvas),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        # Would verify title annotation exists
    
    def test_canvas_version_annotation(self, db_session):
        """Canvas version should be written as numeric annotation."""
        from llm_archive.extractors.chatgpt import ChatGPTExtractor
        
        extractor = ChatGPTExtractor(db_session)
        
        canvas = make_canvas_data(version=5)
        
        dialogue_data = {
            'conversation_id': 'test-conv-canvas-version',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(canvas=canvas),
                },
            },
        }
        
        result = extractor.extract_dialogue(dialogue_data)
        assert result == 'new'


class TestMarkLatestCanvasVersions:
    """Test the mark_latest_canvas_versions utility."""
    
    def test_marks_single_version_as_latest(self, db_session):
        """Single canvas version should be marked as latest."""
        from llm_archive.extractors.chatgpt import (
            ChatGPTExtractor,
            mark_latest_canvas_versions,
        )
        
        extractor = ChatGPTExtractor(db_session)
        
        canvas = make_canvas_data(textdoc_id='doc-single', version=1)
        
        dialogue_data = {
            'conversation_id': 'test-single-version',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(canvas=canvas),
                },
            },
        }
        
        extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        count = mark_latest_canvas_versions(db_session)
        assert count >= 1
    
    def test_marks_highest_version_as_latest(self, db_session):
        """With multiple versions, only highest should be marked latest."""
        from llm_archive.extractors.chatgpt import (
            ChatGPTExtractor,
            mark_latest_canvas_versions,
        )
        
        extractor = ChatGPTExtractor(db_session)
        
        # Create messages with different canvas versions
        mapping = {}
        for i, version in enumerate([1, 3, 2]):  # Out of order
            canvas = make_canvas_data(
                textdoc_id='doc-multi',
                version=version,
            )
            mapping[f'node-{i}'] = {
                'id': f'node-{i}',
                'message': make_message_data(
                    msg_id=f'msg-{i}',
                    canvas=canvas,
                ),
            }
        
        dialogue_data = {
            'conversation_id': 'test-multi-version',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': mapping,
        }
        
        extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        count = mark_latest_canvas_versions(db_session)
        
        # Should mark version 3 as latest (only one per textdoc_id)
        # Would need to verify the correct one is marked


class TestFindWikiGizmoMessages:
    """Test the find_wiki_gizmo_messages utility."""
    
    def test_finds_messages_by_gizmo(self, db_session):
        """Should find all messages with specific gizmo_id."""
        from llm_archive.extractors.chatgpt import (
            ChatGPTExtractor,
            find_wiki_gizmo_messages,
        )
        
        extractor = ChatGPTExtractor(db_session)
        
        # Create messages with different gizmos
        dialogue_data = {
            'conversation_id': 'test-find-gizmo',
            'title': 'Test',
            'create_time': 1700000000,
            'update_time': 1700000000,
            'mapping': {
                'node-1': {
                    'id': 'node-1',
                    'message': make_message_data(
                        msg_id='msg-1',
                        gizmo_id='g-wiki',
                    ),
                },
                'node-2': {
                    'id': 'node-2',
                    'message': make_message_data(
                        msg_id='msg-2',
                        gizmo_id='g-other',
                    ),
                },
                'node-3': {
                    'id': 'node-3',
                    'message': make_message_data(
                        msg_id='msg-3',
                        gizmo_id='g-wiki',
                    ),
                },
            },
        }
        
        extractor.extract_dialogue(dialogue_data)
        db_session.commit()
        
        wiki_messages = find_wiki_gizmo_messages(db_session, 'g-wiki')
        other_messages = find_wiki_gizmo_messages(db_session, 'g-other')
        
        assert len(wiki_messages) == 2
        assert len(other_messages) == 1
    
    def test_returns_empty_for_unknown_gizmo(self, db_session):
        """Should return empty list for unknown gizmo_id."""
        from llm_archive.extractors.chatgpt import find_wiki_gizmo_messages
        
        messages = find_wiki_gizmo_messages(db_session, 'g-nonexistent')
        assert messages == []



---
File: tests/unit/test_cli.py
---
# tests/unit/test_cli.py
"""Unit tests for CLI interface."""

import json
import tempfile
from pathlib import Path

import pytest

from llm_archive.cli import CLI


class TestCLIInit:
    """Tests for CLI initialization."""
    
    def test_cli_default_db_url(self):
        """Test CLI uses default database URL."""
        cli = CLI()
        assert 'postgresql://' in cli.db_url
    
    def test_cli_custom_db_url(self):
        """Test CLI accepts custom database URL."""
        custom_url = "postgresql://user:pass@host:5432/mydb"
        cli = CLI(db_url=custom_url)
        assert cli.db_url == custom_url


class TestCLILoadJSON:
    """Tests for JSON loading."""
    
    def test_load_json_valid(self):
        """Test loading valid JSON file."""
        cli = CLI()
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump([{"id": "test"}], f)
            temp_path = f.name
        
        try:
            data = cli._load_json(temp_path)
            assert data == [{"id": "test"}]
        finally:
            Path(temp_path).unlink()
    
    def test_load_json_missing_file(self):
        """Test loading missing file raises error."""
        cli = CLI()
        
        with pytest.raises(FileNotFoundError):
            cli._load_json("/nonexistent/path.json")
    
    def test_load_json_invalid_format(self):
        """Test loading non-array JSON raises error."""
        cli = CLI()
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump({"not": "an array"}, f)
            temp_path = f.name
        
        try:
            with pytest.raises(ValueError, match="Expected JSON array"):
                cli._load_json(temp_path)
        finally:
            Path(temp_path).unlink()
    
    def test_load_json_empty_array(self):
        """Test loading empty array."""
        cli = CLI()
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump([], f)
            temp_path = f.name
        
        try:
            data = cli._load_json(temp_path)
            assert data == []
        finally:
            Path(temp_path).unlink()
    
    def test_load_json_multiple_items(self):
        """Test loading array with multiple items."""
        cli = CLI()
        
        items = [{"id": "1"}, {"id": "2"}, {"id": "3"}]
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(items, f)
            temp_path = f.name
        
        try:
            data = cli._load_json(temp_path)
            assert data == items
            assert len(data) == 3
        finally:
            Path(temp_path).unlink()



---
File: tests/unit/test_content_classification.py
---
# tests/unit/test_content_classification.py
"""Unit tests for content part classification logic."""

import pytest

from llm_archive.extractors.chatgpt import ChatGPTExtractor
from llm_archive.extractors.claude import ClaudeExtractor


class TestChatGPTClassifyContentPart:
    """Tests for ChatGPT content part classification."""
    
    @pytest.fixture
    def extractor(self, mock_session):
        """Create extractor with mock session."""
        return ChatGPTExtractor(mock_session)
    
    def test_classify_string_text(self, extractor):
        """Test classifying a plain string as text."""
        result = extractor._classify_content_part("Hello world")
        
        assert result['part_type'] == 'text'
        assert result['text_content'] == "Hello world"
        assert result['source_json'] == {'text': "Hello world"}
    
    def test_classify_dict_text(self, extractor):
        """Test classifying a dict with text."""
        part = {'text': 'Some text content'}
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'text'
        assert result['text_content'] == 'Some text content'
    
    def test_classify_image(self, extractor):
        """Test classifying image content."""
        part = {
            'content_type': 'image/png',
            'asset_pointer': 'file-service://abc123',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'image'
        assert result['media_type'] == 'image/png'
        assert result['url'] == 'file-service://abc123'
    
    def test_classify_image_with_url(self, extractor):
        """Test classifying image with direct URL."""
        part = {
            'content_type': 'image/jpeg',
            'url': 'https://example.com/image.jpg',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'image'
        assert result['media_type'] == 'image/jpeg'
        assert result['url'] == 'https://example.com/image.jpg'
    
    def test_classify_audio(self, extractor):
        """Test classifying audio content."""
        part = {
            'content_type': 'audio/mp3',
            'url': 'https://example.com/audio.mp3',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'audio'
        assert result['media_type'] == 'audio/mp3'
        assert result['url'] == 'https://example.com/audio.mp3'
    
    def test_classify_video(self, extractor):
        """Test classifying video content."""
        part = {
            'content_type': 'video/mp4',
            'asset_pointer': 'file-service://video123',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'video'
        assert result['media_type'] == 'video/mp4'
        assert result['url'] == 'file-service://video123'
    
    def test_classify_code(self, extractor):
        """Test classifying code content."""
        part = {
            'content_type': 'code',
            'language': 'python',
            'text': 'print("hello")',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'code'
        assert result['language'] == 'python'
        assert result['text_content'] == 'print("hello")'
    
    def test_classify_code_by_language(self, extractor):
        """Test classifying code by presence of language field."""
        part = {
            'language': 'javascript',
            'code': 'console.log("hi")',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'code'
        assert result['language'] == 'javascript'
    
    def test_classify_unknown_type(self, extractor):
        """Test classifying unknown content type."""
        part = {'content_type': 'exotic/type', 'data': 'something'}
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'exotic/type'
    
    def test_classify_non_dict(self, extractor):
        """Test classifying non-dict, non-string content."""
        result = extractor._classify_content_part(12345)
        
        assert result['part_type'] == 'unknown'
        assert result['source_json'] == {'raw': '12345'}


class TestClaudeClassifyContentPart:
    """Tests for Claude content part classification."""
    
    @pytest.fixture
    def extractor(self, mock_session):
        """Create extractor with mock session."""
        return ClaudeExtractor(mock_session)
    
    def test_classify_text(self, extractor):
        """Test classifying text content."""
        part = {'type': 'text', 'text': 'Hello from Claude'}
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'text'
        assert result['text_content'] == 'Hello from Claude'
    
    def test_classify_thinking(self, extractor):
        """Test classifying thinking content."""
        part = {'type': 'thinking', 'thinking': 'Let me consider this...'}
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'thinking'
        assert result['text_content'] == 'Let me consider this...'
    
    def test_classify_tool_use(self, extractor):
        """Test classifying tool_use content."""
        part = {
            'type': 'tool_use',
            'name': 'web_search',
            'id': 'tool-abc123',
            'input': {'query': 'climate change'},
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'tool_use'
        assert result['tool_name'] == 'web_search'
        assert result['tool_use_id'] == 'tool-abc123'
        assert result['tool_input'] == {'query': 'climate change'}
        assert result['text_content'] == 'climate change'  # Extracted from input.query
    
    def test_classify_tool_use_text_input(self, extractor):
        """Test classifying tool_use with text input."""
        part = {
            'type': 'tool_use',
            'name': 'code_executor',
            'id': 'tool-xyz',
            'input': {'text': 'print(1+1)'},
        }
        result = extractor._classify_content_part(part)
        
        assert result['tool_name'] == 'code_executor'
        assert result['text_content'] == 'print(1+1)'
    
    def test_classify_tool_result_string(self, extractor):
        """Test classifying tool_result with string content."""
        part = {
            'type': 'tool_result',
            'tool_use_id': 'tool-abc123',
            'content': 'Search results: AI news...',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'tool_result'
        assert result['tool_use_id'] == 'tool-abc123'
        assert result['text_content'] == 'Search results: AI news...'
    
    def test_classify_tool_result_list(self, extractor):
        """Test classifying tool_result with list content."""
        part = {
            'type': 'tool_result',
            'tool_use_id': 'tool-abc123',
            'content': [
                {'text': 'First result'},
                {'text': 'Second result'},
            ],
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'tool_result'
        assert result['text_content'] == 'First result\nSecond result'
    
    def test_classify_tool_result_mixed_list(self, extractor):
        """Test classifying tool_result with mixed list content."""
        part = {
            'type': 'tool_result',
            'tool_use_id': 'tool-abc123',
            'content': [
                'Plain string',
                {'text': 'Dict with text'},
            ],
        }
        result = extractor._classify_content_part(part)
        
        assert result['text_content'] == 'Plain string\nDict with text'
    
    def test_classify_tool_result_error(self, extractor):
        """Test classifying tool_result with error flag."""
        part = {
            'type': 'tool_result',
            'tool_use_id': 'tool-abc123',
            'is_error': True,
            'content': 'Error: Something went wrong',
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'tool_result'
        assert result['is_error'] is True
    
    def test_classify_image(self, extractor):
        """Test classifying image content."""
        part = {
            'type': 'image',
            'media_type': 'image/png',
            'source': {'type': 'url', 'url': 'https://example.com/img.png'},
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'image'
        assert result['media_type'] == 'image/png'
        assert result['url'] == 'https://example.com/img.png'
    
    def test_classify_image_base64(self, extractor):
        """Test classifying base64 image (no URL)."""
        part = {
            'type': 'image',
            'media_type': 'image/jpeg',
            'source': {'type': 'base64', 'data': 'abc123...'},
        }
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'image'
        assert result['media_type'] == 'image/jpeg'
        assert 'url' not in result or result.get('url') is None
    
    def test_classify_unknown_type(self, extractor):
        """Test classifying unknown content type."""
        part = {'type': 'custom_widget', 'data': {'foo': 'bar'}}
        result = extractor._classify_content_part(part)
        
        assert result['part_type'] == 'custom_widget'



---
File: tests/unit/test_content_part_annotators.py
---
# tests/unit/test_content_part_annotators.py
"""Unit tests for content-part level annotators."""

import pytest
from datetime import datetime, timezone
from uuid import uuid4

from llm_archive.annotators.content_part import (
    ContentPartData,
    ContentPartAnnotator,
    CodeBlockAnnotator,
    ScriptHeaderAnnotator,
    LatexContentAnnotator,
    WikiLinkContentAnnotator,
    CONTENT_PART_ANNOTATORS,
)
from llm_archive.annotations.core import ValueType, EntityType


# ============================================================
# Test Fixtures
# ============================================================

@pytest.fixture
def content_part_id():
    """Generate a content-part ID."""
    return uuid4()


def make_content_part_data(
    text_content: str = "Test content",
    part_type: str = "text",
    language: str | None = None,
    role: str = "assistant",
    content_part_id: uuid4 = None,
) -> ContentPartData:
    """Create ContentPartData for testing."""
    return ContentPartData(
        content_part_id=content_part_id or uuid4(),
        message_id=uuid4(),
        dialogue_id=uuid4(),
        sequence=0,
        part_type=part_type,
        text_content=text_content,
        language=language,
        role=role,
        created_at=datetime.now(timezone.utc),
    )


# ============================================================
# CodeBlockAnnotator Tests
# ============================================================

class TestCodeBlockAnnotator:
    """Test code block detection at content-part level."""
    
    def test_detects_simple_code_block(self, content_part_id):
        """Should detect basic code blocks."""
        data = make_content_part_data(
            text_content="Here's some code:\n```\nprint('hello')\n```",
            content_part_id=content_part_id,
        )
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code_block' for r in results)
        assert any(r.key == 'code_block_count' for r in results)
        
        count_result = next(r for r in results if r.key == 'code_block_count')
        assert count_result.value == 1
    
    def test_detects_code_block_with_language(self, content_part_id):
        """Should detect code blocks with language specification."""
        data = make_content_part_data(
            text_content="```python\ndef hello():\n    pass\n```",
            content_part_id=content_part_id,
        )
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        lang_results = [r for r in results if r.key == 'code_language']
        assert len(lang_results) == 1
        assert lang_results[0].value == 'python'
    
    def test_counts_multiple_code_blocks(self, content_part_id):
        """Should count multiple code blocks."""
        data = make_content_part_data(
            text_content="```python\ncode1\n```\n\n```javascript\ncode2\n```\n\n```sql\ncode3\n```",
            content_part_id=content_part_id,
        )
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        count_result = next(r for r in results if r.key == 'code_block_count')
        assert count_result.value == 3
        
        lang_results = [r for r in results if r.key == 'code_language']
        langs = {r.value for r in lang_results}
        assert langs == {'python', 'javascript', 'sql'}
    
    def test_no_code_blocks(self, content_part_id):
        """Should return empty for text without code blocks."""
        data = make_content_part_data(
            text_content="This is plain text without any code.",
            content_part_id=content_part_id,
        )
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_skips_non_text_parts(self, content_part_id):
        """Should only process text part_type."""
        # Note: The base class handles this via PART_TYPE_FILTER
        # but the annotate method should also be robust
        data = make_content_part_data(
            text_content="```code```",
            part_type="image",  # Not text
            content_part_id=content_part_id,
        )
        
        # The filter is applied in _iter_content_parts, not annotate
        # So annotate itself will still process, but in real use it won't be called
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        # This should still work since text_content is provided
        results = annotator.annotate(data)
        assert any(r.key == 'has_code_block' for r in results)
    
    def test_empty_text_content(self, content_part_id):
        """Should handle empty text content."""
        data = make_content_part_data(
            text_content="",
            content_part_id=content_part_id,
        )
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_none_text_content(self, content_part_id):
        """Should handle None text content."""
        data = make_content_part_data(
            text_content="placeholder",
            content_part_id=content_part_id,
        )
        data.text_content = None
        
        annotator = CodeBlockAnnotator.__new__(CodeBlockAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0


# ============================================================
# ScriptHeaderAnnotator Tests
# ============================================================

class TestScriptHeaderAnnotator:
    """Test script header detection."""
    
    def test_detects_python_shebang(self, content_part_id):
        """Should detect Python shebang."""
        data = make_content_part_data(
            text_content="#!/usr/bin/env python3\nimport sys",
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_script_header' for r in results)
        
        type_result = next(r for r in results if r.key == 'script_type')
        assert type_result.value == 'python3'
    
    def test_detects_bash_shebang(self, content_part_id):
        """Should detect Bash shebang."""
        data = make_content_part_data(
            text_content="#!/bin/bash\necho hello",
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        type_result = next(r for r in results if r.key == 'script_type')
        assert type_result.value == 'bash'
    
    def test_detects_c_include(self, content_part_id):
        """Should detect C/C++ includes."""
        data = make_content_part_data(
            text_content='#include <stdio.h>\nint main() {}',
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_script_header' for r in results)
        
        type_result = next(r for r in results if r.key == 'script_type')
        assert type_result.value == 'c'
    
    def test_detects_c_include_quotes(self, content_part_id):
        """Should detect C includes with quotes."""
        data = make_content_part_data(
            text_content='#include "myheader.h"',
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_script_header' for r in results)
    
    def test_detects_php_tag(self, content_part_id):
        """Should detect PHP opening tag."""
        data = make_content_part_data(
            text_content="<?php\necho 'Hello';",
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_script_header' for r in results)
        
        type_result = next(r for r in results if r.key == 'script_type')
        assert type_result.value == 'php'
    
    def test_no_script_header(self, content_part_id):
        """Should not detect in plain text."""
        data = make_content_part_data(
            text_content="Just some plain text about programming.",
            content_part_id=content_part_id,
        )
        
        annotator = ScriptHeaderAnnotator.__new__(ScriptHeaderAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0


# ============================================================
# LatexContentAnnotator Tests
# ============================================================

class TestLatexContentAnnotator:
    """Test LaTeX detection at content-part level."""
    
    def test_detects_display_math(self, content_part_id):
        """Should detect $$ display math."""
        data = make_content_part_data(
            text_content="The equation is: $$E = mc^2$$",
            content_part_id=content_part_id,
        )
        
        annotator = LatexContentAnnotator.__new__(LatexContentAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert 'display' in latex_types
    
    def test_detects_inline_math(self, content_part_id):
        """Should detect inline $ math."""
        data = make_content_part_data(
            text_content="The value $x = 5$ is the solution.",
            content_part_id=content_part_id,
        )
        
        annotator = LatexContentAnnotator.__new__(LatexContentAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert 'inline' in latex_types
    
    def test_detects_latex_commands(self, content_part_id):
        """Should detect LaTeX commands."""
        data = make_content_part_data(
            text_content="Use \\frac{a}{b} for fractions.",
            content_part_id=content_part_id,
        )
        
        annotator = LatexContentAnnotator.__new__(LatexContentAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert 'commands' in latex_types
    
    def test_multiple_latex_types(self, content_part_id):
        """Should detect multiple LaTeX types."""
        data = make_content_part_data(
            text_content="Inline $x$ and display $$\\sum_{i=1}^n i$$",
            content_part_id=content_part_id,
        )
        
        annotator = LatexContentAnnotator.__new__(LatexContentAnnotator)
        results = annotator.annotate(data)
        
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert len(latex_types) >= 2
    
    def test_no_latex(self, content_part_id):
        """Should not detect in plain text."""
        data = make_content_part_data(
            text_content="The price is $100 or maybe $200.",
            content_part_id=content_part_id,
        )
        
        annotator = LatexContentAnnotator.__new__(LatexContentAnnotator)
        results = annotator.annotate(data)
        
        # Single $ with numbers shouldn't match inline math pattern
        # (inline pattern requires non-$ chars inside)
        # But this test may be tricky - adjust based on actual behavior
        pass  # May or may not detect - depends on pattern specifics


# ============================================================
# WikiLinkContentAnnotator Tests
# ============================================================

class TestWikiLinkContentAnnotator:
    """Test wiki link detection at content-part level."""
    
    def test_detects_wiki_links(self, content_part_id):
        """Should detect [[wiki links]]."""
        data = make_content_part_data(
            text_content="The [[cat]] is a [[mammal]].",
            content_part_id=content_part_id,
        )
        
        annotator = WikiLinkContentAnnotator.__new__(WikiLinkContentAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_wiki_links' for r in results)
        
        count_result = next(r for r in results if r.key == 'wiki_link_count')
        assert count_result.value == 2
    
    def test_counts_many_wiki_links(self, content_part_id):
        """Should count multiple wiki links."""
        data = make_content_part_data(
            text_content="[[One]] [[Two]] [[Three]] [[Four]] [[Five]]",
            content_part_id=content_part_id,
        )
        
        annotator = WikiLinkContentAnnotator.__new__(WikiLinkContentAnnotator)
        results = annotator.annotate(data)
        
        count_result = next(r for r in results if r.key == 'wiki_link_count')
        assert count_result.value == 5
    
    def test_no_wiki_links(self, content_part_id):
        """Should not detect in plain text."""
        data = make_content_part_data(
            text_content="Regular text with [single brackets] and no wiki links.",
            content_part_id=content_part_id,
        )
        
        annotator = WikiLinkContentAnnotator.__new__(WikiLinkContentAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0


# ============================================================
# ContentPartAnnotator Base Class Tests
# ============================================================

class TestContentPartAnnotatorBase:
    """Test base class attributes and behavior."""
    
    def test_entity_type(self):
        """All content-part annotators should use CONTENT_PART entity type."""
        for annotator_cls in CONTENT_PART_ANNOTATORS:
            assert annotator_cls.ENTITY_TYPE == EntityType.CONTENT_PART
    
    def test_annotators_have_annotation_key(self):
        """All annotators should have ANNOTATION_KEY defined."""
        for annotator_cls in CONTENT_PART_ANNOTATORS:
            assert annotator_cls.ANNOTATION_KEY, f"{annotator_cls.__name__} missing ANNOTATION_KEY"
    
    def test_annotators_have_priority(self):
        """All annotators should have PRIORITY defined."""
        for annotator_cls in CONTENT_PART_ANNOTATORS:
            assert hasattr(annotator_cls, 'PRIORITY')
            assert isinstance(annotator_cls.PRIORITY, int)


# ============================================================
# Registry Tests
# ============================================================

class TestContentPartAnnotatorRegistry:
    """Test the content-part annotator registry."""
    
    def test_all_annotators_in_registry(self):
        """All annotators should be in CONTENT_PART_ANNOTATORS."""
        assert CodeBlockAnnotator in CONTENT_PART_ANNOTATORS
        assert ScriptHeaderAnnotator in CONTENT_PART_ANNOTATORS
        assert LatexContentAnnotator in CONTENT_PART_ANNOTATORS
        assert WikiLinkContentAnnotator in CONTENT_PART_ANNOTATORS
    
    def test_registry_count(self):
        """Registry should have expected number of annotators."""
        assert len(CONTENT_PART_ANNOTATORS) == 4



---
File: tests/unit/test_extractor_utils.py
---
# tests/unit/test_extractor_utils.py
"""Unit tests for extractor utility functions."""

import pytest
from datetime import datetime, timezone

from llm_archive.extractors.base import parse_timestamp, normalize_role, safe_get, compute_content_hash


class TestParseTimestamp:
    """Tests for timestamp parsing."""
    
    def test_parse_epoch_int(self):
        """Test parsing integer epoch timestamp."""
        result = parse_timestamp(1700000000)
        assert result is not None
        assert result.tzinfo is not None
        assert result.year == 2023
    
    def test_parse_epoch_float(self):
        """Test parsing float epoch timestamp."""
        result = parse_timestamp(1700000000.123)
        assert result is not None
        assert result.tzinfo is not None
    
    def test_parse_iso_string(self):
        """Test parsing ISO 8601 string."""
        result = parse_timestamp("2024-01-15T10:00:00Z")
        assert result is not None
        assert result.tzinfo is not None
        assert result.year == 2024
        assert result.month == 1
        assert result.day == 15
    
    def test_parse_iso_string_with_offset(self):
        """Test parsing ISO 8601 with timezone offset."""
        result = parse_timestamp("2024-01-15T10:00:00+05:00")
        assert result is not None
        assert result.tzinfo is not None
    
    def test_parse_none(self):
        """Test parsing None returns None."""
        result = parse_timestamp(None)
        assert result is None
    
    def test_parse_invalid_string(self):
        """Test parsing invalid string returns None."""
        result = parse_timestamp("not a timestamp")
        assert result is None
    
    def test_parse_negative_epoch(self):
        """Test parsing negative epoch (before 1970)."""
        result = parse_timestamp(-1000000)
        assert result is not None
        assert result.year < 1970


class TestNormalizeRole:
    """Tests for role normalization."""
    
    def test_normalize_user(self):
        """Test 'user' stays 'user'."""
        assert normalize_role("user", "chatgpt") == "user"
    
    def test_normalize_assistant(self):
        """Test 'assistant' stays 'assistant'."""
        assert normalize_role("assistant", "chatgpt") == "assistant"
    
    def test_normalize_human_to_user(self):
        """Test 'human' becomes 'user' (Claude format)."""
        assert normalize_role("human", "claude") == "user"
    
    def test_normalize_human_uppercase(self):
        """Test uppercase 'HUMAN' becomes 'user'."""
        assert normalize_role("HUMAN", "claude") == "user"
    
    def test_normalize_system(self):
        """Test 'system' stays 'system'."""
        assert normalize_role("system", "chatgpt") == "system"
    
    def test_normalize_none(self):
        """Test None becomes 'unknown'."""
        assert normalize_role(None, "chatgpt") == "unknown"


class TestSafeGet:
    """Tests for safe dictionary traversal."""
    
    def test_simple_get(self):
        """Test simple key access."""
        data = {"key": "value"}
        assert safe_get(data, "key") == "value"
    
    def test_nested_get(self):
        """Test nested key access."""
        data = {"level1": {"level2": {"level3": "value"}}}
        assert safe_get(data, "level1", "level2", "level3") == "value"
    
    def test_missing_key(self):
        """Test missing key returns default."""
        data = {"key": "value"}
        assert safe_get(data, "missing") is None
        assert safe_get(data, "missing", default="default") == "default"
    
    def test_missing_nested_key(self):
        """Test missing nested key returns default."""
        data = {"level1": {"level2": "value"}}
        assert safe_get(data, "level1", "level2", "level3") is None
    
    def test_non_dict_intermediate(self):
        """Test non-dict intermediate value returns default."""
        data = {"level1": "not a dict"}
        assert safe_get(data, "level1", "level2") is None
    
    def test_none_intermediate(self):
        """Test None intermediate value returns default."""
        data = {"level1": None}
        assert safe_get(data, "level1", "level2") is None


class TestTimestampEdgeCases:
    """Edge case tests for timestamp parsing."""
    
    def test_zero_epoch(self):
        """Test epoch 0 (1970-01-01)."""
        result = parse_timestamp(0)
        assert result is not None
        assert result.year == 1970
    
    def test_very_large_epoch(self):
        """Test very large epoch value."""
        # Year 2100
        result = parse_timestamp(4102444800)
        assert result is not None
        assert result.year == 2100
    
    def test_iso_without_timezone(self):
        """Test ISO string without timezone gets UTC."""
        result = parse_timestamp("2024-01-15T10:00:00")
        assert result is not None
        assert result.tzinfo is not None


class TestComputeContentHash:
    """Tests for content hash computation."""
    
    def test_hash_dict(self):
        """Test hashing a dictionary."""
        data = {'text': 'Hello world', 'role': 'user'}
        result = compute_content_hash(data)
        
        assert result is not None
        assert len(result) == 64  # SHA-256 hex string
    
    def test_hash_string(self):
        """Test hashing a plain string."""
        result = compute_content_hash('Hello world')
        
        assert result is not None
        assert len(result) == 64
    
    def test_hash_is_deterministic(self):
        """Test that same content produces same hash."""
        data = {'message': 'test', 'value': 123}
        
        hash1 = compute_content_hash(data)
        hash2 = compute_content_hash(data)
        
        assert hash1 == hash2
    
    def test_hash_is_order_independent(self):
        """Test that key order doesn't affect hash."""
        data1 = {'a': 1, 'b': 2}
        data2 = {'b': 2, 'a': 1}
        
        hash1 = compute_content_hash(data1)
        hash2 = compute_content_hash(data2)
        
        assert hash1 == hash2
    
    def test_different_content_different_hash(self):
        """Test that different content produces different hash."""
        data1 = {'text': 'Hello'}
        data2 = {'text': 'World'}
        
        hash1 = compute_content_hash(data1)
        hash2 = compute_content_hash(data2)
        
        assert hash1 != hash2
    
    def test_hash_nested_dict(self):
        """Test hashing nested dictionary."""
        data = {
            'content': {
                'parts': ['Hello', {'type': 'code', 'text': 'print(1)'}]
            },
            'metadata': {'author': 'user'}
        }
        
        result = compute_content_hash(data)
        assert len(result) == 64
    
    def test_hash_list(self):
        """Test hashing a list."""
        data = [{'text': 'message 1'}, {'text': 'message 2'}]
        
        result = compute_content_hash(data)
        assert len(result) == 64



---
File: tests/unit/test_models.py
---
# tests/unit/test_models.py
"""Unit tests for SQLAlchemy models - no database required."""

import pytest
from uuid import uuid4
from datetime import datetime, timezone

from llm_archive.models import (
    Dialogue,
    Message,
    ContentPart,
)


class TestDialogueModel:
    """Tests for Dialogue model instantiation."""
    
    def test_create_dialogue_instance(self):
        """Test creating a Dialogue instance."""
        dialogue = Dialogue(
            source='chatgpt',
            source_id='conv-001',
            title='Test Conversation',
            source_json={'test': True},
        )
        
        assert dialogue.source == 'chatgpt'
        assert dialogue.source_id == 'conv-001'
        assert dialogue.title == 'Test Conversation'
        assert dialogue.source_json == {'test': True}
    
    def test_dialogue_with_timestamps(self):
        """Test Dialogue with timestamp fields."""
        now = datetime.now(timezone.utc)
        dialogue = Dialogue(
            source='claude',
            source_id='conv-002',
            created_at=now,
            updated_at=now,
            source_json={},
        )
        
        assert dialogue.created_at == now
        assert dialogue.updated_at == now
    
    def test_dialogue_minimal_fields(self):
        """Test Dialogue with only required fields."""
        dialogue = Dialogue(
            source='chatgpt',
            source_id='conv-003',
            source_json={},
        )
        
        assert dialogue.source == 'chatgpt'
        assert dialogue.source_id == 'conv-003'
        assert dialogue.title is None
        assert dialogue.created_at is None


class TestMessageModel:
    """Tests for Message model instantiation."""
    
    def test_create_message_instance(self):
        """Test creating a Message instance."""
        dialogue_id = uuid4()
        message = Message(
            dialogue_id=dialogue_id,
            source_id='msg-001',
            role='user',
            source_json={'content': 'Hello'},
        )
        
        assert message.dialogue_id == dialogue_id
        assert message.source_id == 'msg-001'
        assert message.role == 'user'
        assert message.source_json == {'content': 'Hello'}
    
    def test_message_with_parent(self):
        """Test Message with parent reference."""
        dialogue_id = uuid4()
        parent_id = uuid4()
        
        message = Message(
            dialogue_id=dialogue_id,
            source_id='msg-002',
            role='assistant',
            parent_id=parent_id,
            source_json={},
        )
        
        assert message.parent_id == parent_id
    
    def test_message_with_author(self):
        """Test Message with author fields."""
        message = Message(
            dialogue_id=uuid4(),
            source_id='msg-003',
            role='user',
            author_id='user-123',
            author_name='John Doe',
            source_json={},
        )
        
        assert message.author_id == 'user-123'
        assert message.author_name == 'John Doe'
    
    def test_message_with_content_hash(self):
        """Test Message with content hash for change detection."""
        message = Message(
            dialogue_id=uuid4(),
            source_id='msg-004',
            role='user',
            content_hash='a' * 64,  # SHA-256 hash
            source_json={},
        )
        
        assert message.content_hash == 'a' * 64
    
    def test_message_with_deleted_at(self):
        """Test Message with soft delete timestamp."""
        now = datetime.now(timezone.utc)
        message = Message(
            dialogue_id=uuid4(),
            source_id='msg-005',
            role='user',
            deleted_at=now,
            source_json={},
        )
        
        assert message.deleted_at == now
    
    def test_message_not_deleted_by_default(self):
        """Test that deleted_at is None by default."""
        message = Message(
            dialogue_id=uuid4(),
            source_id='msg-006',
            role='user',
            source_json={},
        )
        
        assert message.deleted_at is None


class TestContentPartModel:
    """Tests for ContentPart model instantiation."""
    
    def test_create_text_content_part(self):
        """Test creating a text ContentPart."""
        message_id = uuid4()
        part = ContentPart(
            message_id=message_id,
            sequence=0,
            part_type='text',
            text_content='Hello, world!',
            source_json={'type': 'text'},
        )
        
        assert part.message_id == message_id
        assert part.sequence == 0
        assert part.part_type == 'text'
        assert part.text_content == 'Hello, world!'
    
    def test_create_code_content_part(self):
        """Test creating a code ContentPart with language."""
        part = ContentPart(
            message_id=uuid4(),
            sequence=1,
            part_type='code',
            text_content='print("hello")',
            language='python',
            source_json={'type': 'code', 'language': 'python'},
        )
        
        assert part.part_type == 'code'
        assert part.language == 'python'
        assert part.text_content == 'print("hello")'
    
    def test_create_image_content_part(self):
        """Test creating an image ContentPart with media type and URL."""
        part = ContentPart(
            message_id=uuid4(),
            sequence=0,
            part_type='image',
            media_type='image/png',
            url='https://example.com/image.png',
            source_json={'type': 'image'},
        )
        
        assert part.part_type == 'image'
        assert part.media_type == 'image/png'
        assert part.url == 'https://example.com/image.png'
    
    def test_create_tool_use_content_part(self):
        """Test creating a tool_use ContentPart."""
        part = ContentPart(
            message_id=uuid4(),
            sequence=0,
            part_type='tool_use',
            tool_name='web_search',
            tool_use_id='tool-123',
            tool_input={'query': 'test search'},
            source_json={'type': 'tool_use'},
        )
        
        assert part.part_type == 'tool_use'
        assert part.tool_name == 'web_search'
        assert part.tool_use_id == 'tool-123'
        assert part.tool_input == {'query': 'test search'}
    
    def test_create_tool_result_content_part(self):
        """Test creating a tool_result ContentPart."""
        part = ContentPart(
            message_id=uuid4(),
            sequence=1,
            part_type='tool_result',
            tool_use_id='tool-123',
            text_content='Search results: ...',
            is_error=False,
            source_json={'type': 'tool_result'},
        )
        
        assert part.part_type == 'tool_result'
        assert part.tool_use_id == 'tool-123'
        assert part.is_error is False


class TestModelTableNames:
    """Tests for model table name configuration."""
    
    def test_dialogue_table_name(self):
        """Test Dialogue uses raw schema."""
        assert Dialogue.__tablename__ == 'dialogues'
        assert Dialogue.__table__.schema == 'raw'
    
    def test_message_table_name(self):
        """Test Message uses raw schema."""
        assert Message.__tablename__ == 'messages'
        assert Message.__table__.schema == 'raw'
    
    def test_content_part_table_name(self):
        """Test ContentPart uses raw schema."""
        assert ContentPart.__tablename__ == 'content_parts'
        assert ContentPart.__table__.schema == 'raw'
    



---
File: tests/unit/test_prompt_response.py
---
# tests/unit/test_prompt_response.py
"""Unit tests for prompt-response builders and annotators."""

import pytest
from datetime import datetime, timezone
from uuid import uuid4

from llm_archive.annotators.prompt_response import (
    PromptResponseData,
    PromptResponseAnnotator,
    WikiCandidateAnnotator,
    NaiveTitleAnnotator,
    HasCodeAnnotator,
    HasLatexAnnotator,
)
from llm_archive.annotations.core import ValueType, EntityType, AnnotationResult


# ============================================================
# Test Fixtures
# ============================================================

@pytest.fixture
def pr_id():
    """Generate a prompt-response ID."""
    return uuid4()


def make_pr_data(
    prompt_text: str = "Test prompt",
    response_text: str = "Test response",
    pr_id: uuid4 = None,
    response_role: str = 'assistant',
    prompt_role: str = 'user',
) -> PromptResponseData:
    """Create PromptResponseData for testing."""
    return PromptResponseData(
        prompt_response_id=pr_id or uuid4(),
        dialogue_id=uuid4(),
        prompt_message_id=uuid4(),
        response_message_id=uuid4(),
        prompt_text=prompt_text,
        response_text=response_text,
        prompt_word_count=len(prompt_text.split()) if prompt_text else 0,
        response_word_count=len(response_text.split()) if response_text else 0,
        prompt_role=prompt_role,
        response_role=response_role,
        created_at=datetime.now(timezone.utc),
    )


# ============================================================
# WikiCandidateAnnotator Tests
# ============================================================

class TestWikiCandidateAnnotator:
    """Test wiki article detection."""
    
    def test_detects_wiki_links(self, pr_id):
        """Should detect responses with wiki links."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="# Cats\n\nCats are [[mammals]] that are [[domesticated]].",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        # Should have both exchange_type and wiki_link_count annotations
        assert len(results) == 2
        
        exchange_type_result = next(r for r in results if r.key == 'exchange_type')
        assert exchange_type_result.value == 'wiki_article'
        assert exchange_type_result.value_type == ValueType.STRING
        assert exchange_type_result.reason == 'wiki_links_detected'
        
        count_result = next(r for r in results if r.key == 'wiki_link_count')
        assert count_result.value == 2
        assert count_result.value_type == ValueType.NUMERIC
    
    def test_high_confidence_multiple_links(self, pr_id):
        """Should have higher confidence with 3+ wiki links."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="[[Cats]] are [[mammals]]. They eat [[mice]] and [[birds]].",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        exchange_type_result = next(r for r in results if r.key == 'exchange_type')
        assert exchange_type_result.confidence == 0.95
    
    def test_lower_confidence_single_link(self, pr_id):
        """Should have lower confidence with just 1-2 links."""
        data = make_pr_data(
            prompt_text="Tell me about cats",
            response_text="Cats are [[mammals]].",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        exchange_type_result = next(r for r in results if r.key == 'exchange_type')
        assert exchange_type_result.confidence == 0.8
    
    def test_no_wiki_links(self, pr_id):
        """Should not detect if no wiki links."""
        data = make_pr_data(
            prompt_text="Tell me about cats",
            response_text="Cats are mammals. They are cute.",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_skips_non_assistant(self, pr_id):
        """Should skip non-assistant responses."""
        data = make_pr_data(
            prompt_text="Write [[wiki]] style",
            response_text="Here's [[content]]",
            pr_id=pr_id,
            response_role='user',  # Not assistant
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_counts_links_correctly(self, pr_id):
        """Should count wiki links correctly."""
        data = make_pr_data(
            response_text="[[One]] [[Two]] [[Three]] [[Four]] [[Five]]",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        count_result = next(r for r in results if r.key == 'wiki_link_count')
        assert count_result.value == 5
    
    def test_handles_empty_brackets(self, pr_id):
        """Should count empty brackets as potential links."""
        data = make_pr_data(
            response_text="Empty [[]] brackets and [[valid]] link",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        count_result = next(r for r in results if r.key == 'wiki_link_count')
        assert count_result.value == 2


# ============================================================
# NaiveTitleAnnotator Tests
# ============================================================

class TestNaiveTitleAnnotator:
    """Test naive title extraction."""
    
    def test_extracts_markdown_h1(self, pr_id):
        """Should extract # Title."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="# The Domestic Cat\n\n[[Cats]] are mammals...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'The Domestic Cat'
        assert results[0].key == 'proposed_title'
        assert results[0].value_type == ValueType.STRING
        assert results[0].reason == 'markdown_header'
    
    def test_extracts_markdown_h2(self, pr_id):
        """Should extract ## Title."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="## Feline History\n\nThe history of cats...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'Feline History'
        assert results[0].reason == 'markdown_header'
    
    def test_extracts_markdown_h3(self, pr_id):
        """Should extract ### Title."""
        data = make_pr_data(
            response_text="### Deep Section\n\nContent here...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'Deep Section'
    
    def test_extracts_bold_title(self, pr_id):
        """Should extract **Title**."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="**The Domestic Cat**\n\n[[Cats]] are mammals...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'The Domestic Cat'
        assert results[0].reason == 'bold_header'
    
    def test_extracts_bold_with_subtitle(self, pr_id):
        """Should extract **Title** - Subtitle pattern."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="**Felis catus** - The Domestic Cat\n\nContent...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'Felis catus'
        assert results[0].reason == 'bold_header_with_suffix'
    
    def test_no_title_preamble(self, pr_id):
        """Should return nothing if first line is preamble."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="Sure, here's an article about cats:\n\n# The Domestic Cat\n\n...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        # This is expected - naive extractor misses the title
        # because first line is a preamble
        assert len(results) == 0
    
    def test_no_title_plain_text(self, pr_id):
        """Should return nothing if no clear title format."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="Cats have been domesticated for thousands of years...",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_skips_non_assistant(self, pr_id):
        """Should skip non-assistant responses."""
        data = make_pr_data(
            prompt_text="# My Title",
            response_text="# Another Title",
            pr_id=pr_id,
            response_role='user',
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_empty_response(self, pr_id):
        """Should handle empty response."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_none_response(self, pr_id):
        """Should handle None response."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="placeholder",
            pr_id=pr_id,
        )
        data.response_text = None  # Override
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_whitespace_only_first_line(self, pr_id):
        """Should skip whitespace-only first lines."""
        data = make_pr_data(
            response_text="   \n# Real Title\n\nContent",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        # .strip() is called on the document, so the title should be extracted.
        assert len(results) == 1
    
    def test_strips_title_whitespace(self, pr_id):
        """Should strip whitespace from extracted title."""
        data = make_pr_data(
            response_text="#   Spaced Title   \n\nContent",
            pr_id=pr_id,
        )
        
        annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 1
        assert results[0].value == 'Spaced Title'


# ============================================================
# Annotation Filter Tests (class attributes)
# ============================================================

class TestAnnotatorFilters:
    """Test annotation filter attributes."""
    
    def test_wiki_candidate_has_no_requirements(self):
        """WikiCandidateAnnotator should have no prerequisites."""
        assert WikiCandidateAnnotator.REQUIRES_FLAGS == []
        assert WikiCandidateAnnotator.REQUIRES_STRINGS == []
        assert WikiCandidateAnnotator.SKIP_IF_FLAGS == []
        assert WikiCandidateAnnotator.SKIP_IF_STRINGS == []
    
    def test_naive_title_requires_wiki(self):
        """NaiveTitleAnnotator should require wiki_article."""
        assert ('exchange_type', 'wiki_article') in NaiveTitleAnnotator.REQUIRES_STRINGS
    
    def test_annotator_metadata(self):
        """Check annotator class metadata."""
        assert WikiCandidateAnnotator.ENTITY_TYPE == EntityType.PROMPT_RESPONSE
        assert WikiCandidateAnnotator.ANNOTATION_KEY == 'exchange_type'
        assert WikiCandidateAnnotator.VALUE_TYPE == ValueType.STRING
        
        assert NaiveTitleAnnotator.ENTITY_TYPE == EntityType.PROMPT_RESPONSE
        assert NaiveTitleAnnotator.ANNOTATION_KEY == 'proposed_title'
        assert NaiveTitleAnnotator.VALUE_TYPE == ValueType.STRING
        
        # Wiki detection should run before title extraction
        assert WikiCandidateAnnotator.PRIORITY > NaiveTitleAnnotator.PRIORITY
    
    def test_custom_annotator_with_filters(self):
        """Test defining custom annotator with filters."""
        
        class PreambleDetector(PromptResponseAnnotator):
            ANNOTATION_KEY = 'has_preamble'
            VALUE_TYPE = ValueType.FLAG
            REQUIRES_STRINGS = [('exchange_type', 'wiki_article')]
            SKIP_IF_FLAGS = ['preamble_checked']
            
            def annotate(self, data):
                return []
        
        assert PreambleDetector.REQUIRES_STRINGS == [('exchange_type', 'wiki_article')]
        assert PreambleDetector.SKIP_IF_FLAGS == ['preamble_checked']


# ============================================================
# AnnotationResult Tests
# ============================================================

class TestAnnotationResult:
    """Test AnnotationResult dataclass behavior."""
    
    def test_result_with_reason(self, pr_id):
        """Results should include reason when provided."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="# Cats\n\n[[Cats]] are mammals.",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        exchange_type_result = next(r for r in results if r.key == 'exchange_type')
        assert exchange_type_result.reason == 'wiki_links_detected'
    
    def test_key_is_required(self, pr_id):
        """Key should always be set on results."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="# Title\n\n[[link]]",
            pr_id=pr_id,
        )
        
        wiki_annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        wiki_results = wiki_annotator.annotate(data)
        
        title_annotator = NaiveTitleAnnotator.__new__(NaiveTitleAnnotator)
        title_results = title_annotator.annotate(data)
        
        for result in wiki_results + title_results:
            assert result.key is not None
    
    def test_value_type_is_set(self, pr_id):
        """Results should have explicit value_type."""
        data = make_pr_data(
            prompt_text="Write about cats",
            response_text="# Title\n\n[[link1]] [[link2]] [[link3]]",
            pr_id=pr_id,
        )
        
        annotator = WikiCandidateAnnotator.__new__(WikiCandidateAnnotator)
        results = annotator.annotate(data)
        
        # Should have string and numeric results
        string_results = [r for r in results if r.value_type == ValueType.STRING]
        numeric_results = [r for r in results if r.value_type == ValueType.NUMERIC]
        
        assert len(string_results) >= 1
        assert len(numeric_results) >= 1


# ============================================================
# PromptResponseData Tests
# ============================================================

class TestPromptResponseData:
    """Test PromptResponseData dataclass."""
    
    def test_all_fields_accessible(self):
        """All fields should be accessible."""
        data = make_pr_data(
            prompt_text="Hello",
            response_text="World",
        )
        
        assert data.prompt_text == "Hello"
        assert data.response_text == "World"
        assert data.prompt_role == 'user'
        assert data.response_role == 'assistant'
        assert isinstance(data.prompt_response_id, type(uuid4()))
        assert isinstance(data.dialogue_id, type(uuid4()))
    
    def test_word_counts_calculated(self):
        """Word counts should be calculated from text."""
        data = make_pr_data(
            prompt_text="one two three",
            response_text="four five six seven",
        )
        
        assert data.prompt_word_count == 3
        assert data.response_word_count == 4
    
    def test_handles_none_text(self):
        """Should handle None text gracefully."""
        data = PromptResponseData(
            prompt_response_id=uuid4(),
            dialogue_id=uuid4(),
            prompt_message_id=uuid4(),
            response_message_id=uuid4(),
            prompt_text=None,
            response_text=None,
            prompt_word_count=0,
            response_word_count=0,
            prompt_role='user',
            response_role='assistant',
            created_at=datetime.now(timezone.utc),
        )
        
        assert data.prompt_text is None
        assert data.response_text is None


# ============================================================
# HasCodeAnnotator Tests
# ============================================================

class TestHasCodeAnnotator:
    """Test code detection annotator."""
    
    def test_detects_code_blocks(self, pr_id):
        """Should detect ``` code blocks."""
        data = make_pr_data(
            response_text="Here's some code:\n```python\nprint('hello')\n```",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        flag_results = [r for r in results if r.key == 'has_code']
        assert len(flag_results) == 1
        assert flag_results[0].value_type == ValueType.FLAG
        assert flag_results[0].confidence >= 0.9
        
        evidence_results = [r for r in results if r.key == 'code_evidence']
        evidence_values = {r.value for r in evidence_results}
        assert 'code_block' in evidence_values
    
    def test_detects_shebang(self, pr_id):
        """Should detect shebang lines."""
        data = make_pr_data(
            response_text="#!/usr/bin/env python\nprint('hello')",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'shebang' in evidence_values
    
    def test_detects_c_include(self, pr_id):
        """Should detect C/C++ includes."""
        data = make_pr_data(
            response_text='#include <stdio.h>\nint main() { return 0; }',
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'c_include' in evidence_values
    
    def test_detects_python_function(self, pr_id):
        """Should detect Python function definitions."""
        data = make_pr_data(
            response_text="def hello_world():\n    print('hello')",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'python_function' in evidence_values
    
    def test_detects_js_function(self, pr_id):
        """Should detect JavaScript function definitions."""
        data = make_pr_data(
            response_text="function hello() {\n  console.log('hello');\n}",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'js_function' in evidence_values
    
    def test_detects_arrow_function(self, pr_id):
        """Should detect arrow functions."""
        data = make_pr_data(
            response_text="const hello = (name) => console.log(`Hello ${name}`);",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'arrow_function' in evidence_values
    
    def test_detects_python_import(self, pr_id):
        """Should detect Python imports."""
        data = make_pr_data(
            response_text="import pandas as pd\nfrom datetime import datetime",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_code' for r in results)
        evidence_values = {r.value for r in results if r.key == 'code_evidence'}
        assert 'python_import' in evidence_values
    
    def test_no_code_in_plain_text(self, pr_id):
        """Should not detect code in plain text."""
        data = make_pr_data(
            response_text="Cats are wonderful pets. They like to sleep and play.",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_skips_non_assistant(self, pr_id):
        """Should skip non-assistant responses."""
        data = make_pr_data(
            response_text="```python\nprint('hello')\n```",
            pr_id=pr_id,
            response_role='user',
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_multiple_evidence_types(self, pr_id):
        """Should detect multiple evidence types."""
        data = make_pr_data(
            response_text="```python\nimport os\ndef main():\n    pass\n```",
            pr_id=pr_id,
        )
        
        annotator = HasCodeAnnotator.__new__(HasCodeAnnotator)
        results = annotator.annotate(data)
        
        evidence_results = [r for r in results if r.key == 'code_evidence']
        assert len(evidence_results) >= 2  # code_block + python_function + python_import


# ============================================================
# HasLatexAnnotator Tests
# ============================================================

class TestHasLatexAnnotator:
    """Test LaTeX detection annotator."""
    
    def test_detects_display_math(self, pr_id):
        """Should detect display math $$...$$."""
        data = make_pr_data(
            response_text="The equation is: $$E = mc^2$$",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert 'display' in latex_types
    
    def test_detects_bracket_display_math(self, pr_id):
        """Should detect \\[...\\] display math."""
        data = make_pr_data(
            response_text="The integral is: \\[\\int_0^\\infty e^{-x} dx = 1\\]",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
    
    def test_detects_latex_commands(self, pr_id):
        """Should detect LaTeX commands."""
        data = make_pr_data(
            response_text="Use \\frac{a}{b} for fractions and \\sqrt{x} for roots.",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
        latex_types = {r.value for r in results if r.key == 'latex_type'}
        assert 'commands' in latex_types
    
    def test_detects_greek_letters(self, pr_id):
        """Should detect Greek letter commands."""
        data = make_pr_data(
            response_text="The angle \\theta is measured from \\alpha to \\omega.",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert any(r.key == 'has_latex' for r in results)
    
    def test_no_latex_in_plain_text(self, pr_id):
        """Should not detect LaTeX in plain text."""
        data = make_pr_data(
            response_text="The value of pi is approximately 3.14159.",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_skips_non_assistant(self, pr_id):
        """Should skip non-assistant responses."""
        data = make_pr_data(
            response_text="$$E = mc^2$$",
            pr_id=pr_id,
            response_role='user',
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        assert len(results) == 0
    
    def test_high_confidence_for_display_math(self, pr_id):
        """Should have high confidence for display math."""
        data = make_pr_data(
            response_text="$$\\sum_{i=1}^n i = \\frac{n(n+1)}{2}$$",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        flag_result = next(r for r in results if r.key == 'has_latex')
        assert flag_result.confidence >= 0.9
    
    def test_lower_confidence_for_commands_only(self, pr_id):
        """Should have lower confidence for commands without display math."""
        data = make_pr_data(
            response_text="Use \\alpha and \\beta for parameters.",
            pr_id=pr_id,
        )
        
        annotator = HasLatexAnnotator.__new__(HasLatexAnnotator)
        results = annotator.annotate(data)
        
        flag_result = next(r for r in results if r.key == 'has_latex')
        assert flag_result.confidence < 0.9


# ============================================================
# Annotator Registry Tests
# ============================================================

class TestAnnotatorRegistry:
    """Test the annotator registry and runner."""
    
    def test_all_annotators_in_registry(self):
        """All annotators should be in PROMPT_RESPONSE_ANNOTATORS."""
        from llm_archive.annotators.prompt_response import PROMPT_RESPONSE_ANNOTATORS
        
        assert WikiCandidateAnnotator in PROMPT_RESPONSE_ANNOTATORS
        assert NaiveTitleAnnotator in PROMPT_RESPONSE_ANNOTATORS
        assert HasCodeAnnotator in PROMPT_RESPONSE_ANNOTATORS
        assert HasLatexAnnotator in PROMPT_RESPONSE_ANNOTATORS
    
    def test_annotators_have_unique_keys(self):
        """Each annotator should have a unique ANNOTATION_KEY."""
        from llm_archive.annotators.prompt_response import PROMPT_RESPONSE_ANNOTATORS
        
        keys = [cls.ANNOTATION_KEY for cls in PROMPT_RESPONSE_ANNOTATORS]
        assert len(keys) == len(set(keys)), "Duplicate ANNOTATION_KEYs found"
    
    def test_priority_ordering(self):
        """Annotators should have distinct priorities for deterministic ordering."""
        from llm_archive.annotators.prompt_response import PROMPT_RESPONSE_ANNOTATORS
        
        priorities = [cls.PRIORITY for cls in PROMPT_RESPONSE_ANNOTATORS]
        # Note: Priorities don't have to be unique, but it helps with debugging
        assert len(priorities) == len(PROMPT_RESPONSE_ANNOTATORS)


